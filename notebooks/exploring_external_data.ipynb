{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551918a-204c-40e4-bb4a-9635f980f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa98451-8b1a-481b-b493-bc2579a123ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c81ca-53f0-4d6a-961e-0785e02121c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"../data/curated/external/concatenated.csv\"\n",
    "df = (\n",
    "    pl.read_csv(data, infer_schema_length=40000)\n",
    "    .with_row_count(name=\"id_\")\n",
    "    .drop(\"id\")\n",
    "    .rename({\"id_\": \"id\"})\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c526eaa-8702-4948-ac8c-27352703129b",
   "metadata": {},
   "source": [
    "One important thing here is to look for AI generated essays using the same prompt as we have on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae675e1c-6fab-426c-b02f-66b6a0759d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"generated\") == 1).unique(\"text\").filter(\n",
    "    (pl.col(\"prompt_id\") == \"1\") | (pl.col(\"prompt_id\") == \"0\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8836f551-3f76-4c66-b7d1-b63a4b6b9b31",
   "metadata": {},
   "source": [
    "Look at by removing duplicated essays (as we're collecting from different repositories so duplicates can happen), and also selecting just the essays we know about the `prompt_id` was used, we end up with not too much data. But I believe that this is lot more significant to the model, and also an simple strategy to start the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f052f13-da97-43eb-a6ce-0a5f224d06f8",
   "metadata": {},
   "source": [
    "You can see that there is a lot of others prompts, mostly from ArguGPT repository, but others also has `prompt_ids` from the PERSUADE Corpus generated by AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cbb7a-aa86-44f9-a505-e339fd57e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"generated\") == 1).unique(\"text\").select(\"prompt_id\").unique(\n",
    "    \"prompt_id\"\n",
    ").to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a780511-3427-4cb3-9767-cfb75f8858aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
