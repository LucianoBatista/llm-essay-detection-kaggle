Here you'll find what each experiment on the repository does. Some experiments will contains ETL process, others will have model training, others just validating some ideas.

# Exp 01

In this process I'm creating a new dataset to use on the competition. This dataset will contain a lot of essays written by humans and AI generated as well. I'm doing this because the original dataset from the competition contains almost none ai generated essays, and also because the leaderboard (test data) is evaluated on essays that was written also by another 5 prompts not showed on the training data.

The best part is that those prompts are comming from a well known corpus, the PERSUADE corpus.

The data generated here will contains some columns that will help us to validate different datasets from the community, I'm putting a "kaggle_repo" flag, to indicate from where the data come from.

The data looks like:

```sh
shape: (54_691, 6)
┌───────┬───────────┬───────────────────────────────────┬───────────┬───────────────┬─────────────┐
│ id    ┆ prompt_id ┆ text                              ┆ generated ┆ model         ┆ kaggle_repo │
│ ---   ┆ ---       ┆ ---                               ┆ ---       ┆ ---           ┆ ---         │
│ u32   ┆ str       ┆ str                               ┆ i64       ┆ str           ┆ i64         │
╞═══════╪═══════════╪═══════════════════════════════════╪═══════════╪═══════════════╪═════════════╡
│ 0     ┆ 0         ┆ Advantages of Limiting Car Usage… ┆ 1         ┆ gpt-3.5-turbo ┆ 1           │
│ 1     ┆ 0         ┆ Advantages of Limiting Car Usage… ┆ 1         ┆ gpt-3.5-turbo ┆ 1           │
│ 2     ┆ 0         ┆ Limiting car usage has numerous … ┆ 1         ┆ gpt-3.5-turbo ┆ 1           │
│ 3     ┆ 0         ┆ The passages provided discuss th… ┆ 1         ┆ gpt-3.5-turbo ┆ 1           │
│ …     ┆ …         ┆ …                                 ┆ …         ┆ …             ┆ …           │
│ 54687 ┆ -1        ┆ Working alone, students do not h… ┆ 0         ┆ human         ┆ 9           │
│ 54688 ┆ -1        ┆ "A problem is a chance for you t… ┆ 0         ┆ human         ┆ 9           │
│ 54689 ┆ -1        ┆ Many people disagree with Albert… ┆ 0         ┆ human         ┆ 9           │
│ 54690 ┆ -1        ┆ Do you think that failure is the… ┆ 0         ┆ human         ┆ 9           │
└───────┴───────────┴───────────────────────────────────┴───────────┴───────────────┴─────────────┘
```

Filtering duplicates and human written text (just for now), we endup with a small dataset with 823 AI generated text.

I'm planning for the next iteration, to use this 823 plus the data from the competition to create our classifier.

# Exp 02

In this experiment I tuned a RoBERTa base model, with a classification head with the output of two classes:

- 1: Generated by AI
- 0: Written by a student

The objective here was to understand how I could upload a pre-trained model to the competition, without use the internet on the submission notebook.

Besides, with this approach I want to validate also if using a transformer encoder based model could output a good metric right away or not.

I got a very poor result on the public leaderboard with a score of 0.596, where strategies with tfidf + traditional classifiers have beeing more helpful with a ROC AUC of 0.960.

Some param that I used:

- epochs: 20 and 100
- base model: 768 dimensions
- pretrained tokenizer: sentece-piece
- data: from the competition + external data of AI generated (I did not used others human written text)

# Exp 03

As I mentioned before, the best performances are comming from a Kaggle Grandmaster that published a very good idea of use of a tuning of the tokenizer + tfidf strategies + traditional classifiers. So I had to experiment that.

As this start I'm not just copying others solutions, and I'm using the time to learn new strategies and the what of some techniques are working and others not.

This run was very direct, and I basically created a simple pipeline with the tfidf vectorizer and a MultinomialNB model, and run it on a database. This time I used more data during the experiment, as you can see from `src/exp_03/exp_03.py`, look how simple was the pipe:

```python
pipeline = Pipeline(
    [
        ("tfidf", TfidfVectorizer(max_features=4500)),
        ("clf", MultinomialNB()),
    ]
)
```

The performance was almost 0.7, where I believe that the max feature param help the model to not overfit.

# Exp 04

This is an extension of the experiment 03, where I did some tuning on a tokenizer. I used [this link](https://huggingface.co/learn/nlp-course/chapter6/2?fw=pt) to understand how to tuning a tokenizer, I did not used a training from scratch, supposing that this could work better.

Here we need to do some heavy work to load some files to public datasets in order to use the notebook without internet connection for the submission.

I did some improviment on the public leaderboard, but did not came to the top as my score was 0.795.

This shows that this approach really has some benefits.

I also did some small changes on this experiment, on data, tfidf params, MultinomialNB params, but nothing result in a score higher than 0.795 for this run.
